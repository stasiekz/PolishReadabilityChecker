; General purpose tokeniser configuration. Contains no language-specific rules.
; Employed token types: t (word token or letters mixed with digits), p (punctuation or symbol), n (sequence of digits)

[input]
; use only default sentence splitting rules and split by one newline (see segment.srx)
; TODO: does it really work?
	token_type=t
	srx=segment.srx
	srx_language=xx_one
	initial_whitespace=newline

[layer:always]
; always split on symbols (S) and punctuation (P)
	class=split
	separators=[\p{S} \p{P}]
	separator_token_type=p


[layer:n_classify]
; recognise numbers
	class=regexp
	process_types=t
	type:n=[\p{Nd}]+

[layers]
	layer=always
	layer=n_classify

[debug]
	format=$bs|\t$orth\t$type\t$ws\n
